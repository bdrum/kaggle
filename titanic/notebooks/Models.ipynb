{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T18:06:41.571459Z",
     "start_time": "2022-02-22T18:06:40.359304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Survived      891 non-null    int64  \n",
      " 1   Pclass        891 non-null    int64  \n",
      " 2   Sex           891 non-null    object \n",
      " 3   Age           891 non-null    float64\n",
      " 4   SibSp         891 non-null    int64  \n",
      " 5   Parch         891 non-null    int64  \n",
      " 6   Fare          891 non-null    float64\n",
      " 7   Embarked      889 non-null    object \n",
      " 8   Title         891 non-null    object \n",
      " 9   CabLet        891 non-null    object \n",
      " 10  Alone         891 non-null    int64  \n",
      " 11  Familiars     891 non-null    int64  \n",
      " 12  TicketLetter  891 non-null    object \n",
      " 13  LenName       891 non-null    int64  \n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib widget\n",
    "\n",
    "import titanic.data.load\n",
    "import titanic.data.wrangling as wrng\n",
    "\n",
    "\n",
    "train_df_orig, test_df_orig = titanic.data.load.from_csv()\n",
    "\n",
    "train_df = wrng.wrangling(train_df_orig)\n",
    "test_df = wrng.wrangling(test_df_orig)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, train_df_orig.Survived, test_size=0.3, random_state=50)\n",
    "\n",
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T19:19:12.759265Z",
     "start_time": "2022-02-07T19:02:33.939365Z"
    }
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from titanic.data.preprocessing import preprocessor\n",
    "\n",
    "n_est = [800,900,1000]\n",
    "max_depth = [2,5,10]\n",
    "max_depth.append(None)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "#     \"preprocessor__num__norm\": ['l1', 'l2', 'max'],\n",
    "#     Number of trees in random forest\n",
    "    \"rand_for__n_estimators\": n_est,\n",
    "    # Number of features to consider at every split\n",
    "    \"rand_for__max_features\": ['auto', 'sqrt'],\n",
    "    # Maximum number of levels in tree\n",
    "    \"rand_for__max_depth\": max_depth,\n",
    "    # Minimum number of samples required to split a node\n",
    "    \"rand_for__min_samples_split\": [2, 5, 10],\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    \"rand_for__min_samples_leaf\": [2, 4, 8],\n",
    "    # Method of selecting samples for training each tree\n",
    "    \"rand_for__bootstrap\": [True, False],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "best_params = {'bootstrap': True,\n",
    " 'max_depth': None,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 800}\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"rand_for\", RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=10, verbose=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T19:33:02.991163Z",
     "start_time": "2022-02-07T19:33:02.778964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best fit params: {'rand_for__bootstrap': True, 'rand_for__max_depth': None, 'rand_for__max_features': 'sqrt', 'rand_for__min_samples_leaf': 2, 'rand_for__min_samples_split': 2, 'rand_for__n_estimators': 800}\n",
      "model score: 0.840\n"
     ]
    }
   ],
   "source": [
    "est = grid_search\n",
    "print(\"best fit params:\", est.best_params_)\n",
    "# est = clf\n",
    "print(\"model score: %.3f\" % est.score(X_test, y_test))\n",
    "y_pred = est.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T19:33:38.183923Z",
     "start_time": "2022-02-07T19:33:34.558626Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.77k/2.77k [00:02<00:00, 1.37kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Titanic - Machine Learning from Disaster"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kaggle \n",
    "\n",
    "file = r'../data/submission.csv'\n",
    "competition = 'titanic'\n",
    "message = ''\n",
    "test_df_orig['Survived'] = y_pred\n",
    "test_df_orig[['PassengerId', 'Survived']].to_csv(file, index=False)\n",
    "\n",
    "\n",
    "kaggle.api.competition_submit(file,message,competition)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-22T18:07:08.117Z"
    }
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "import titanic.data.preprocessing\n",
    "\n",
    "n_est = [800,900,1000]\n",
    "max_depth = [2,5,10]\n",
    "max_depth.append(None)\n",
    "param_grid = {\n",
    "    #  \"preprocessor__num__norm\": ['l1', 'l2', 'max'],\n",
    "    # The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "    \"grad_boost__n_estimators\": n_est,\n",
    "    # Learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
    "    \"grad_boost__learning_rate\": [0.5,1,2],\n",
    "    # Maximum number of levels in tree\n",
    "    \"grad_boost__max_depth\": max_depth,\n",
    "    # Controls the random seed given to each Tree estimator at each boosting iteration. In addition, it controls the random permutation of the features at each split (see Notes for more details). It also controls the random splitting of the training data to obtain a validation set if n_iter_no_change is not None. Pass an int for reproducible output across multiple function calls.\n",
    "    \"grad_boost__random_state\": [20, 30, 42],\n",
    "    # The loss function to be optimized. ‘deviance’ refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss ‘exponential’ gradient boosting recovers the AdaBoost algorithm.\n",
    "    \"grad_boost__loss\": ['deviance', 'exponential'],\n",
    "    # The function to measure the quality of a split. Supported criteria are ‘friedman_mse’ for the mean squared error with improvement score by Friedman, ‘squared_error’ for mean squared error, and ‘mae’ for the mean absolute error. The default value of ‘friedman_mse’ is generally the best as it can provide a better approximation in some cases.\n",
    "    \"grad_boost__criterion\": ['friedman_mse', 'squared_error', 'mse', 'mae'],\n",
    "    # Number of features to consider at every split\n",
    "    \"grad_boost__max_features\": ['auto', 'sqrt', 'log2'],\n",
    "\n",
    "}\n",
    "\n",
    "preprocessor = titanic.data.preprocessing.preprocessing()\n",
    "\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"grad_boost\", GradientBoostingClassifier())]\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=10, verbose=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "# clf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5aec7ed6c202a036617c9ad53f2a030d4723c67d4d81c99f7ce90f0c2a0c47b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "497px",
    "width": "303px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
